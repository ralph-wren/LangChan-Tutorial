{
 "cells": [
  {
   "cell_type": "code",
   "id": "aed1306081e3b621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:53:03.614336600Z",
     "start_time": "2025-12-19T17:52:55.029331300Z"
    }
   },
   "source": [
    "#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "dotenv.load_dotenv() #加载当前目录下的 .env 文件\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\") # 默认使用 gpt-3.5-turbo\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='“大模型”通常指的是在人工智能和机器学习领域中，规模非常庞大的深度学习模型。这类模型拥有非常多的参数（通常达到数亿甚至数百亿以上），能够处理和学习大量的复杂数据，从而在多种任务中表现出强大的能力。\\n\\n具体来说，大模型的特点包括：\\n\\n1. **参数量巨大**：相比传统模型，大模型的参数数量极多，能够捕捉更多的数据特征和复杂模式。\\n2. **计算资源需求高**：训练和推理过程需要大量的计算资源，包括高性能的GPU或TPU集群。\\n3. **泛化能力强**：由于模型容量大，可以适应多样化的任务，如自然语言处理（NLP）、图像识别、语音识别等。\\n4. **多任务能力**：一些大模型经过大规模预训练，具备良好的迁移学习能力，可以在多个下游任务中表现优异。\\n5. **代表模型**：例如OpenAI的GPT系列、Google的BERT和PaLM、Facebook的LLaMA等。\\n\\n总结而言，“大模型”是指那些基于深度学习，拥有极大参数规模和强大计算能力，能够处理复杂任务并提供高质量结果的人工智能模型。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 279, 'prompt_tokens': 12, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-2025qDGRZIXXFCjl0ODUK9IdFDtDf', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b37be-5749-74f0-a942-be55e3ca244d-0' usage_metadata={'input_tokens': 12, 'output_tokens': 279, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "52018d8a6147d2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:41:53.792527800Z",
     "start_time": "2025-12-19T17:41:52.396892800Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "6f5efb58f845486a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:07:06.756191200Z",
     "start_time": "2025-12-19T17:06:59.102406Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者\"),\n",
    "(\"user\", \"{input}\") # {input}为变量\n",
    "])\n",
    "# 我们可以把prompt和具体llm的调用和在一起。\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\": \"大模型中的LangChain是什么?\"})\n",
    "print(message)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain 是一个用于构建基于大语言模型（Large Language Models, LLMs）应用的开源框架。它旨在帮助开发者更高效地构建复杂的语言模型驱动系统，通过模块化的设计，将语言模型与外部工具、数据和流程无缝集成，从而扩展大模型的能力和应用场景。\\n\\n### LangChain 的核心功能和特点包括：\\n\\n1. **链式调用（Chains）**  \\n   LangChain 允许开发者通过“链”来组合和管理一系列语言模型调用及相关操作。一个链可以包含多个步骤，每个步骤处理输入、调用模型或工具，再传递结果到下一步骤，实现复杂的业务逻辑。\\n\\n2. **多样化的记忆机制（Memory）**  \\n   支持对话历史、上下文状态的管理，帮助模型更好地理解当前对话环境，实现连续、上下文相关的交互体验。\\n\\n3. **集成外部工具和数据源**  \\n   LangChain 支持将语言模型与数据库、API、搜索引擎、知识库等系统连接，使模型能够查询实时数据、执行操作、检索信息，提升模型的实用性和准确性。\\n\\n4. **多模态和多模型支持**  \\n   除了文本模型，LangChain 也能支持图像、语音等多模态数据处理，并且可以组合不同的模型，以发挥各自优势。\\n\\n5. **开发效率和部署便利**  \\n   提供丰富的预构建模块、模板和示例，降低开发门槛；支持多种编程语言接口，使得搭建和维护大模型应用更加便捷。\\n\\n### 应用场景示例\\n\\n- 智能问答系统  \\n- 自动文档生成和总结  \\n- 多轮对话机器人  \\n- 个性化推荐与搜索辅助  \\n- 自动化工作流和任务执行  \\n\\n---\\n\\n总之，LangChain 是一个连接和扩展大语言模型能力的重要工具，帮助开发者将强大的语言理解和生成能力应用于更复杂、更实用的场景中。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 457, 'prompt_tokens': 29, 'total_tokens': 486, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-2025trvRM7rqZQuJZTa0EfICIKnt5', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b3794-37c3-7081-a172-c3904a8eb059-0' usage_metadata={'input_tokens': 29, 'output_tokens': 457, 'total_tokens': 486, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "48a6b96e1f8c4a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:42:03.915379500Z",
     "start_time": "2025-12-19T17:42:01.643521200Z"
    }
   },
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者。\"),\n",
    "(\"user\", \"{input}\")\n",
    "])\n",
    "# 使用输出解析器\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么? 用JSON格式回复，问题用question，回答用answer\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'LangChain是什么?',\n",
       " 'answer': 'LangChain是一个用于构建基于语言模型的应用程序的开发框架。它提供了工具和接口，帮助开发者将大型语言模型（如OpenAI的GPT系列）与外部数据源、计算资源和应用逻辑集成，实现复杂的自然语言处理任务和智能应用。'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "35cd1d964e4fab28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:07:18.399591100Z",
     "start_time": "2025-12-19T17:07:12.349573300Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者。输出格式要求：{format_instructions}\"),\n",
    "(\"user\", \"{input}\")\n",
    "])\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么?\",\"format_instructions\":output_parser.get_format_instructions()})\n",
    "# 使用输出解析器"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangChain',\n",
       " 'description': 'LangChain 是一个用于构建基于语言模型（如 GPT-4）的应用程序的框架。它提供了一套工具和组件，使开发者能够轻松地将语言模型与外部数据源、记忆机制、链式调用等功能结合，构建复杂且交互性强的自然语言处理应用。',\n",
       " '主要功能': ['链式调用（Chains）：将多个语言模型调用和数据处理步骤串联起来，形成复杂的处理流程。',\n",
       "  '记忆（Memory）：支持对话上下文的持久化，提升对话的连续性和自然度。',\n",
       "  '集成外部数据源：连接数据库、API、文件等，丰富语言模型的输入。',\n",
       "  '工具使用（Agents）：自动选择和调用多种工具，引导语言模型完成复杂任务。',\n",
       "  '多模态支持：结合文本、代码、表格等多种数据形式。'],\n",
       " '适用场景': ['智能问答系统', '对话机器人', '知识检索与管理', '自动化文本处理与生成', '教育与培训辅助工具'],\n",
       " '官方网站': 'https://langchain.com',\n",
       " '开源地址': 'https://github.com/hwchase17/langchain'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:43:23.994594300Z",
     "start_time": "2025-12-19T17:43:20.574512400Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的文档数量: 1\n",
      "第一个文档的内容长度: 2902\n",
      "分割后的文档数量: 7\n",
      "向量存储创建成功!\n"
     ]
    }
   ],
   "execution_count": 34,
   "source": [
    "# 导入和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "\n",
    "# 设置超时时间\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://yiqiml.xyz/topic/7\",\n",
    "    # 可以添加请求头和超时设置\n",
    "    header_template={\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    ")\n",
    "# 设置超时时间（秒）\n",
    "loader.requests_kwargs = {'timeout': 10}\n",
    "docs = loader.load()\n",
    "print(f\"加载的文档数量: {len(docs)}\")\n",
    "if docs:\n",
    "    print(f\"第一个文档的内容长度: {len(docs[0].page_content)}\")\n",
    "\n",
    "\n",
    "# 对于嵌入模型，这里通过 API调用RAG(检索增强生成)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(f\"分割后的文档数量: {len(documents)}\")\n",
    "\n",
    "# 只有在有文档时才创建向量存储\n",
    "if documents:\n",
    "    vector = FAISS.from_documents(documents, embeddings)\n",
    "    print(\"向量存储创建成功!\")\n",
    "else:\n",
    "    print(\"错误: 没有文档可以创建向量存储\")\n",
    "\n",
    "\n"
   ],
   "id": "777aa90cb1d3c5a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:44:14.091673400Z",
     "start_time": "2025-12-19T17:44:10.742786900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "retriever = vector.as_retriever()\n",
    "retriever.search_kwargs = {\"k\": 3}\n",
    "docs = retriever.invoke(\"故事讲了什么内容\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "你是一个问答机器人。\n",
    "你的任务是根据下述给定的已知信息回答用户问题。\n",
    "确保你的回复完全依据下述已知信息。不要编造答案。\n",
    "如果下述已知信息不足以回答用户的问题，请直接回复\"我无法回答您的问题\"。\n",
    "已知信息:\n",
    "{info}\n",
    "用户问：\n",
    "{question}\n",
    "请用中文回答用户问题。\n",
    "\"\"\"\n",
    "# 7.得到提示词模版对象\n",
    "template = PromptTemplate.from_template(prompt_template)\n",
    "# 8.得到提示词对象\n",
    "prompt = template.format(info=docs, question='故事内容？')\n",
    "## 9. 调用LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "id": "c696ac654467cb6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "故事内容讲述了一个妻子在喂奶和亲密关系之间的生活。妻子在回家后会先洗澡，然后换上家居服，与她的儿子亲密互动。虽然自宝宝出生以来，夫妻关系几乎没有性行为，但妻子仍然体贴地为丈夫提供按摩。整个故事展示了妻子对家庭的投入以及夫妻间默契的互动。\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "18b05172405c3583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:45:01.975758900Z",
     "start_time": "2025-12-19T17:45:00.807856Z"
    }
   },
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"中华人民共和国民法典是新中国第一部以法典命名的法律。\"),\n",
    "    Document(page_content=\"民法典于2021年1月1日起施行。\"),\n",
    "]\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"CivilCodeRetriever\",\n",
    "    \"搜索有关中华人民共和国民法典的信息。关于中华人民共和国民法典的任何问题，您必须使用此工具!\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "772211acb1ea4238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:45:52.048871800Z",
     "start_time": "2025-12-19T17:45:51.981793200Z"
    }
   },
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. retriever -> tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"CivilCodeRetriever\",\n",
    "    description=\"用于查询故事内容\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]\n",
    "\n",
    "# 2. prompt（不再用 hub）\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个根据工具返回结果回答问题的助手\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 3. tool calling agent\n",
    "agent = create_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# 4. executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 5. invoke\n",
    "agent_executor.invoke({\"input\": \"故事内容\"})\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.agents.agent'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mretriever\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_retriever_tool\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_agent\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magents\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magent\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AgentExecutor\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mprompts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatPromptTemplate\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# 1. retriever -> tool\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'langchain.agents.agent'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "dc006edc00a6ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:39:42.571142700Z",
     "start_time": "2025-12-19T17:39:42.530034600Z"
    }
   },
   "source": [
    "import langchain.agents as a\n",
    "print(dir(a))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgentState', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'create_agent', 'factory', 'middleware', 'structured_output']\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e842b8d9784143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
