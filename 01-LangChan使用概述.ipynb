{
 "cells": [
  {
   "cell_type": "code",
   "id": "aed1306081e3b621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:15:30.069989Z",
     "start_time": "2025-12-22T11:15:25.686978Z"
    }
   },
   "source": [
    "#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "dotenv.load_dotenv() #加载当前目录下的 .env 文件\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\") # 默认使用 gpt-3.5-turbo\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='“大模型”通常是指参数规模非常大、能力较强的机器学习模型，尤其是在自然语言处理（NLP）领域的大规模预训练模型。它们通过在海量数据上进行训练，能够掌握丰富的语言知识和复杂的模式，从而在各种任务中表现出良好的泛化能力。\\n\\n具体来说，大模型的特点包括：\\n\\n1. **参数规模大**：通常包含数亿到数千亿甚至更多的参数。参数越多，模型的表达能力越强，但也需要更多的计算资源。\\n\\n2. **训练数据量大**：使用海量、多样化的数据进行预训练，使模型能够学习到丰富的语言规律和知识。\\n\\n3. **通用性强**：预训练后可以通过微调应用于多种具体任务，如文本生成、机器翻译、问答系统、文本分类等。\\n\\n4. **计算资源需求高**：训练和推理过程需要大量的计算能力，通常依赖高性能GPU或TPU集群。\\n\\n典型的大模型例子有OpenAI的GPT系列（如GPT-3、GPT-4）、Google的BERT、PaLM等。这些模型在自然语言理解和生成领域推动了技术的快速发展。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 267, 'prompt_tokens': 12, 'total_tokens': 279, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-2025NKBoz25YnI6co2QFnMPpwijY9', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b45c5-6faa-72b0-90be-488bab04e7f9-0' usage_metadata={'input_tokens': 12, 'output_tokens': 267, 'total_tokens': 279, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "52018d8a6147d2e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:16:37.919972Z",
     "start_time": "2025-12-22T11:16:36.472434Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "response = llm.invoke(\"Hello!\")\n",
    "\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "6f5efb58f845486a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:16:47.173988Z",
     "start_time": "2025-12-22T11:16:42.357973Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者\"),\n",
    "(\"user\", \"{input}\") # {input}为变量\n",
    "])\n",
    "# 我们可以把prompt和具体llm的调用和在一起。\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\": \"大模型中的LangChain是什么?\"})\n",
    "print(message)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain 是一个用于构建大语言模型（Large Language Models, LLM）应用的开源框架。它旨在简化和加速基于大模型的智能应用开发，通过提供模块化组件和工具，使开发者能够更高效地集成、扩展和管理语言模型的功能。\\n\\n具体来说，LangChain 具备以下几个核心特点：\\n\\n1. **模型集成**  \\n   支持多种大型语言模型（如 OpenAI GPT、Anthropic Claude 等）的无缝接入，方便开发者选择和切换不同的模型服务。\\n\\n2. **链式调用（Chain）设计**  \\n   允许开发者将多个模型调用、数据处理步骤、业务逻辑串联成“链”，实现复杂的多轮对话、任务自动化和推理流程。\\n\\n3. **数据增强**  \\n   内置丰富的数据加载和处理模块，支持外部文档、数据库、API 等多源信息的接入，增强模型的上下文理解和回答准确度。\\n\\n4. **工具和代理**  \\n   支持结合各种工具（如搜索引擎、计算器、知识库查询等）协同工作，实现模型能力的扩展和任务的自动执行。\\n\\n5. **调试与监控**  \\n   提供调试链条执行过程的能力，帮助开发者优化模型调用和数据流，提升应用稳定性和性能。\\n\\n总的来说，LangChain 是连接大语言模型与实际应用需求的桥梁，帮助开发者快速构建具备对话、问答、生成、推理等多样功能的智能系统，是当前大模型生态中极具影响力的技术框架之一。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 366, 'prompt_tokens': 29, 'total_tokens': 395, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-CpYCMBwa6z3tQjlJ9EQXIghTQo3ne', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b45c6-9b53-7992-b422-cd45d7bb5ecb-0' usage_metadata={'input_tokens': 29, 'output_tokens': 366, 'total_tokens': 395, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "48a6b96e1f8c4a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:47:16.523532Z",
     "start_time": "2025-12-22T11:47:13.959166Z"
    }
   },
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者。\"),\n",
    "(\"user\", \"{input}\")\n",
    "])\n",
    "# 使用输出解析器\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么? 用JSON格式回复，问题用question，回答用answer\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'LangChain是什么?',\n",
       " 'answer': 'LangChain是一个用于构建基于语言模型应用的开发框架。它提供了一系列工具和组件，帮助开发者将大型语言模型（如GPT）与外部数据源、记忆功能以及复杂的工作流相结合，从而构建智能对话系统、问答系统和自动化工具。LangChain支持链式调用语言模型，简化多步推理和任务执行。'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "35cd1d964e4fab28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T17:07:18.399591100Z",
     "start_time": "2025-12-19T17:07:12.349573300Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者。输出格式要求：{format_instructions}\"),\n",
    "(\"user\", \"{input}\")\n",
    "])\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么?\",\"format_instructions\":output_parser.get_format_instructions()})\n",
    "# 使用输出解析器"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangChain',\n",
       " 'description': 'LangChain 是一个用于构建基于语言模型（如 GPT-4）的应用程序的框架。它提供了一套工具和组件，使开发者能够轻松地将语言模型与外部数据源、记忆机制、链式调用等功能结合，构建复杂且交互性强的自然语言处理应用。',\n",
       " '主要功能': ['链式调用（Chains）：将多个语言模型调用和数据处理步骤串联起来，形成复杂的处理流程。',\n",
       "  '记忆（Memory）：支持对话上下文的持久化，提升对话的连续性和自然度。',\n",
       "  '集成外部数据源：连接数据库、API、文件等，丰富语言模型的输入。',\n",
       "  '工具使用（Agents）：自动选择和调用多种工具，引导语言模型完成复杂任务。',\n",
       "  '多模态支持：结合文本、代码、表格等多种数据形式。'],\n",
       " '适用场景': ['智能问答系统', '对话机器人', '知识检索与管理', '自动化文本处理与生成', '教育与培训辅助工具'],\n",
       " '官方网站': 'https://langchain.com',\n",
       " '开源地址': 'https://github.com/hwchase17/langchain'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:17:13.025751Z",
     "start_time": "2025-12-22T11:17:08.185260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "\n",
    "# 设置超时时间\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://edition.cnn.com/politics/live-news/trump-epstein-news-12-21-25\",\n",
    "    # 可以添加请求头和超时设置\n",
    "    header_template={\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    ")\n",
    "# 设置超时时间（秒）\n",
    "loader.requests_kwargs = {'timeout': 10}\n",
    "docs = loader.load()\n",
    "print(f\"加载的文档数量: {len(docs)}\")\n",
    "if docs:\n",
    "    print(f\"第一个文档的内容长度: {len(docs[0].page_content)}\")\n",
    "\n",
    "\n",
    "# 对于嵌入模型，这里通过 API调用RAG(检索增强生成)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(f\"分割后的文档数量: {len(documents)}\")\n",
    "\n",
    "# 只有在有文档时才创建向量存储\n",
    "if documents:\n",
    "    vector = FAISS.from_documents(documents, embeddings)\n",
    "    print(\"向量存储创建成功!\")\n",
    "else:\n",
    "    print(\"错误: 没有文档可以创建向量存储\")\n",
    "\n",
    "\n"
   ],
   "id": "777aa90cb1d3c5a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的文档数量: 1\n",
      "第一个文档的内容长度: 22714\n",
      "分割后的文档数量: 56\n",
      "向量存储创建成功!\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:18:43.382895Z",
     "start_time": "2025-12-22T11:18:40.092079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "retriever = vector.as_retriever()\n",
    "retriever.search_kwargs = {\"k\": 3}\n",
    "docs = retriever.invoke(\"what the news is about?\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "你是一个问答机器人。\n",
    "你的任务是根据下述给定的已知信息回答用户问题。\n",
    "确保你的回复完全依据下述已知信息。不要编造答案。\n",
    "已知信息:\n",
    "{info}\n",
    "用户问：\n",
    "{question}\n",
    "请用中文回答用户问题。\n",
    "\"\"\"\n",
    "# 7.得到提示词模版对象\n",
    "template = PromptTemplate.from_template(prompt_template)\n",
    "# 8.得到提示词对象\n",
    "prompt = template.format(info=docs, question='大概介绍下新闻内容')\n",
    "## 9. 调用LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "id": "c696ac654467cb6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据已知信息，这则新闻报道主要内容是关于2025年12月21日特朗普政府与爱泼斯坦相关文件的公开。报道中提到，司法部网站上至少有一张包含特朗普总统照片的图片被移除了。新闻来源于CNN，涉及特朗普与爱泼斯坦案件的文件发布和相关新闻更新。具体细节内容没有更多披露。\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "18b05172405c3583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:13:46.511623Z",
     "start_time": "2025-12-22T11:13:45.074783Z"
    }
   },
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"中华人民共和国民法典是新中国第一部以法典命名的法律。\"),\n",
    "    Document(page_content=\"民法典于2021年1月1日起施行。\"),\n",
    "]\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"CivilCodeRetriever\",\n",
    "    \"搜索有关中华人民共和国民法典的信息。关于中华人民共和国民法典的任何问题，您必须使用此工具!\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "772211acb1ea4238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T09:51:51.843513Z",
     "start_time": "2025-12-22T09:51:44.056766Z"
    }
   },
   "source": [
    "# Chat Model - 对话\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI()\n",
    "result = chat.invoke(\"你好\")  # AI会回复你\n",
    "print(result.content)\n",
    "\n",
    "# Embeddings - 向量化\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector = embeddings.embed_query(\"机器学习\")  # 变成一串数字\n",
    "print(f\"向量维度: {len(vector)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！有什么我可以帮忙的吗？\n",
      "向量维度: 1536\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "dc006edc00a6ce6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:10:30.312742Z",
     "start_time": "2025-12-22T11:10:30.264398Z"
    }
   },
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# 创建记忆存储\n",
    "message_history = ChatMessageHistory()\n",
    "\n",
    "# 保存对话\n",
    "message_history.add_user_message(\"我叫张三\")\n",
    "message_history.add_ai_message(\"你好张三，很高兴认识你!\")\n",
    "\n",
    "# 查看记忆\n",
    "print(\"对话历史:\")\n",
    "for msg in message_history.messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对话历史:\n",
      "human: 我叫张三\n",
      "ai: 你好张三，很高兴认识你!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:30:38.301265Z",
     "start_time": "2025-12-22T11:30:35.205879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# 创建记忆存储\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 创建带记忆的对话链\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个友好的助手\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\") # 默认使用 gpt-3.5-turbo\n",
    "chain = prompt | model\n",
    "\n",
    "# 包装成带记忆的链\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 使用（会自动记住对话）\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"我叫张三\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user123\"}}\n",
    ")\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"我叫什么名字？\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user123\"}}\n",
    ")\n",
    "# AI会回答：你叫张三\n",
    "print(response1.content)\n",
    "print(response2.content)\n"
   ],
   "id": "dfc1874c74cfc18b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好，张三！很高兴认识你。有什么我可以帮忙的吗？\n",
      "你叫张三。有什么我可以帮你的吗，张三？\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:37:00.352172Z",
     "start_time": "2025-12-22T11:36:50.135464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# 初始化聊天模型\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # 使用更经济的模型\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 构建消息列表\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一个专业的Python编程助手\"),\n",
    "    HumanMessage(content=\"如何实现单例模式？\"),\n",
    "]\n",
    "\n",
    "# 调用模型\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "# 多轮对话\n",
    "messages.append(AIMessage(content=response.content))\n",
    "messages.append(HumanMessage(content=\"能给个代码示例吗？\"))\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ],
   "id": "b522c9ca4535a56a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在Python中实现单例模式有多种方法。以下是几种常见的实现方式：\n",
      "\n",
      "### 方法 1：使用模块\n",
      "Python模块本身就是单例的，因为模块只会被导入一次。\n",
      "\n",
      "```python\n",
      "# singleton.py\n",
      "class Singleton:\n",
      "    def some_method(self):\n",
      "        print(\"Doing something.\")\n",
      "\n",
      "singleton_instance = Singleton()\n",
      "```\n",
      "\n",
      "在其他地方使用时，只需导入`singleton_instance`即可：\n",
      "\n",
      "```python\n",
      "from singleton import singleton_instance\n",
      "\n",
      "singleton_instance.some_method()\n",
      "```\n",
      "\n",
      "### 方法 2：使用类变量\n",
      "\n",
      "```python\n",
      "class Singleton:\n",
      "    _instance = None\n",
      "\n",
      "    def __new__(cls, *args, **kwargs):\n",
      "        if not cls._instance:\n",
      "            cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n",
      "        return cls._instance\n",
      "\n",
      "# 使用示例\n",
      "s1 = Singleton()\n",
      "s2 = Singleton()\n",
      "\n",
      "print(s1 is s2)  # 输出: True\n",
      "```\n",
      "\n",
      "### 方法 3：使用装饰器\n",
      "\n",
      "```python\n",
      "def singleton(cls):\n",
      "    instances = {}\n",
      "    def get_instance(*args, **kwargs):\n",
      "        if cls not in instances:\n",
      "            instances[cls] = cls(*args, **kwargs)\n",
      "        return instances[cls]\n",
      "    return get_instance\n",
      "\n",
      "@singleton\n",
      "class Singleton:\n",
      "    def some_method(self):\n",
      "        print(\"Doing something.\")\n",
      "\n",
      "# 使用示例\n",
      "s1 = Singleton()\n",
      "s2 = Singleton()\n",
      "\n",
      "print(s1 is s2)  # 输出: True\n",
      "```\n",
      "\n",
      "### 方法 4：使用元类\n",
      "\n",
      "```python\n",
      "class SingletonMeta(type):\n",
      "    _instances = {}\n",
      "\n",
      "    def __call__(cls, *args, **kwargs):\n",
      "        if cls not in cls._instances:\n",
      "            instance = super().__call__(*args, **kwargs)\n",
      "            cls._instances[cls] = instance\n",
      "        return cls._instances[cls]\n",
      "\n",
      "class Singleton(metaclass=SingletonMeta):\n",
      "    def some_method(self):\n",
      "        print(\"Doing something.\")\n",
      "\n",
      "# 使用示例\n",
      "s1 = Singleton()\n",
      "s2 = Singleton()\n",
      "\n",
      "print(s1 is s2)  # 输出: True\n",
      "```\n",
      "\n",
      "以上是几种实现单例模式的方法。你可以根据自己的需求选择合适的方法。\n",
      "当然可以！下面是一个具体的代码示例，使用了**类变量**的方法来实现单例模式。这个示例展示了如何创建一个单例类，并验证其实例是唯一的。\n",
      "\n",
      "```python\n",
      "class Singleton:\n",
      "    _instance = None  # 类变量，用于存储单例实例\n",
      "\n",
      "    def __new__(cls, *args, **kwargs):\n",
      "        if not cls._instance:  # 如果实例不存在，则创建新实例\n",
      "            cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n",
      "        return cls._instance  # 返回唯一实例\n",
      "\n",
      "    def some_method(self):\n",
      "        print(\"Doing something.\")\n",
      "\n",
      "# 使用示例\n",
      "if __name__ == \"__main__\":\n",
      "    s1 = Singleton()  # 创建第一个实例\n",
      "    s2 = Singleton()  # 创建第二个实例\n",
      "\n",
      "    # 验证s1和s2是同一个实例\n",
      "    print(s1 is s2)  # 输出: True\n",
      "\n",
      "    # 调用方法\n",
      "    s1.some_method()  # 输出: Doing something.\n",
      "```\n",
      "\n",
      "### 解释\n",
      "1. **`__new__` 方法**: 这是一个特殊的方法，在实例化对象之前被调用。我们在这里检查 `_instance` 是否已经存在。如果不存在，则调用父类的 `__new__` 方法创建一个新实例，并将其赋值给 `_instance`。如果 `_instance` 已经存在，则直接返回它。\n",
      "\n",
      "2. **`some_method` 方法**: 这是一个普通的方法，示例中用于展示如何使用单例类的实例。\n",
      "\n",
      "3. **实例化与验证**: 在 `if __name__ == \"__main__\":` 块中，我们创建了两个实例 `s1` 和 `s2`，并使用 `print(s1 is s2)` 验证它们是否是同一个实例。\n",
      "\n",
      "运行这个代码，你将看到输出为：\n",
      "```\n",
      "True\n",
      "Doing something.\n",
      "```\n",
      "\n",
      "这表明 `s1` 和 `s2` 确实是同一个实例，并且调用了 `some_method` 方法。\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:39:19.680558Z",
     "start_time": "2025-12-22T11:39:15.367007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 初始化\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# 单个文本向量化\n",
    "vector = embeddings.embed_query(\"机器学习是什么？\")\n",
    "print(f\"向量维度: {len(vector)}\")\n",
    "\n",
    "# 批量向量化\n",
    "texts = [\"文本1\", \"文本2\", \"文本3\"]\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "# 计算相似度\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "query_vec = embeddings.embed_query(\"深度学习\")\n",
    "doc_vec = embeddings.embed_query(\"神经网络\")\n",
    "similarity = cosine_similarity(query_vec, doc_vec)\n",
    "print(f\"相似度: {similarity}\")\n"
   ],
   "id": "3977ccf3769274f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量维度: 1536\n",
      "相似度: 0.34774392436715224\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:41:46.802072Z",
     "start_time": "2025-12-22T11:41:43.603111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# 成本追踪\n",
    "with get_openai_callback() as cb:\n",
    "    response = model.invoke(\"你好\")\n",
    "    print(f\"Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Cost: ${cb.total_cost}\")\n",
    "\n",
    "# 自动重试\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=10)\n",
    ")\n",
    "def call_model_with_retry(prompt):\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "result = call_model_with_retry(\"你好\")\n",
    "print(result.content)"
   ],
   "id": "b929e054e600f75a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 18\n",
      "Cost: $1.9200000000000003e-05\n",
      "你好！有什么我可以帮忙的吗？\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "65e67e4302540147"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:56:26.604852Z",
     "start_time": "2025-12-22T11:56:19.723362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 初始化模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 系统消息模板\n",
    "system_template = \"你是一个{expertise}专家，擅长{skill}。\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# 用户消息模板\n",
    "human_template = \"{user_input}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 组合\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_prompt,\n",
    "    human_prompt\n",
    "])\n",
    "\n",
    "# 创建输出解析器\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 创建链\n",
    "chain = chat_prompt | llm | output_parser\n",
    "\n",
    "# 使用\n",
    "result = chain.invoke({\n",
    "    \"expertise\": \"数据分析\",\n",
    "    \"skill\": \"Python和SQL\",\n",
    "    \"user_input\": \"如何分析用户行为数据？\"\n",
    "})\n",
    "\n",
    "print(result)"
   ],
   "id": "4395b1da2b45feb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分析用户行为数据通常涉及多个步骤，包括数据收集、预处理、探索性数据分析（EDA）、建模以及结果解读。以下是一个详细的流程：\n",
      "\n",
      "### 1. 数据收集\n",
      "- **数据源**：获取用户行为数据可以通过日志数据、数据库、API等方式。\n",
      "- **数据类型**：包含用户的交互数据（如点击、浏览、购买），时间戳以及用户属性（如年龄、性别）。\n",
      "\n",
      "### 2. 数据预处理\n",
      "- **缺失值处理**：识别并处理缺失数据，方法包括填补、删除等。\n",
      "- **数据清洗**：去除噪声数据和重复数据。\n",
      "- **数据转化**：对数据进行类型转换（如时间字符串转化为日期时间格式）。\n",
      "\n",
      "### 3. 探索性数据分析（EDA）\n",
      "- **描述性统计**：计算基本统计量（如均值、标准差、频率分布等）。\n",
      "- **数据可视化**：使用图形工具（如Matplotlib、Seaborn等）可视化用户行为，找出模式和趋势。\n",
      "  - 折线图：分析时间序列数据。\n",
      "  - 条形图/饼图：分析各类行为的分布。\n",
      "  - 热图：分析用户行为之间的相关性。\n",
      "\n",
      "### 4. 用户细分\n",
      "- **群体划分**：使用聚类算法（如K-Means、层次聚类）对用户进行细分，找出不同类型的用户群体。\n",
      "- **行为路径分析**：分析用户在应用或网站中的行为路径，识别关键转化点。\n",
      "\n",
      "### 5. 建模\n",
      "- **预测模型**：根据用户行为数据构建预测模型（如用户流失预测、购买预测等），可以使用机器学习算法（如逻辑回归、决策树、随机森林等）。\n",
      "- **A/B测试**：针对不同策略进行对比测试，分析不同用户群体的反应。\n",
      "\n",
      "### 6. 结果解读与优化\n",
      "- **结果分析**：解释模型结果，以及用户行为分析所带来的洞见。\n",
      "- **决策支持**：根据分析结果制定产品策略、市场策略或用户体验优化方案。\n",
      "\n",
      "### 7. 持续监控与迭代\n",
      "- 定期监控用户行为数据，进行持续分析和优化，根据新的数据调整策略。\n",
      "\n",
      "### 实用工具\n",
      "- **Python库**：pandas、NumPy、scikit-learn、Matplotlib、Seaborn等。\n",
      "- **SQL**：用于数据存储和管理，方便地进行数据提取和处理。\n",
      "\n",
      "通过上述步骤，可以全面系统地分析用户行为数据，并根据数据产生有效的商业洞察和决策。\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:57:56.840026Z",
     "start_time": "2025-12-22T11:57:56.755802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "# 定义示例\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"happy\",\n",
    "        \"output\": \"sad\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"tall\",\n",
    "        \"output\": \"short\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"hot\",\n",
    "        \"output\": \"cold\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 示例格式化模板\n",
    "example_template = \"\"\"\n",
    "Input: {input}\n",
    "Output: {output}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Few-shot模板\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出以下词的反义词：\",\n",
    "    suffix=\"Input: {word}\\nOutput:\",\n",
    "    input_variables=[\"word\"]\n",
    ")\n",
    "\n",
    "# 使用\n",
    "print(few_shot_prompt.format(word=\"big\"))\n"
   ],
   "id": "5dd1d63ab9466a5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出以下词的反义词：\n",
      "\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "\n",
      "\n",
      "Input: hot\n",
      "Output: cold\n",
      "\n",
      "\n",
      "Input: big\n",
      "Output:\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c25cc7614f663df1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
