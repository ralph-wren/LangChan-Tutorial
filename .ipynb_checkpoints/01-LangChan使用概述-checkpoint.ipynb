{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "dotenv.load_dotenv() #加载当前目录下的 .env 文件\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\") # 默认使用 gpt-3.5-turbo\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ],
   "id": "aed1306081e3b621",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:51:42.693907200Z",
     "start_time": "2025-12-19T13:51:40.963177700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "52018d8a6147d2e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:44:19.797601100Z",
     "start_time": "2025-12-19T13:44:12.663482800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者\"),\n",
    "(\"user\", \"{input}\") # {input}为变量\n",
    "])\n",
    "# 我们可以把prompt和具体llm的调用和在一起。\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\": \"大模型中的LangChain是什么?\"})\n",
    "print(message)"
   ],
   "id": "6f5efb58f845486a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChain 是一种用于构建基于大型语言模型（Large Language Models, LLMs）应用的框架或工具库。它旨在帮助开发者更高效地创建、管理和组合多种语言模型能力，以实现复杂的自然语言处理任务。\\n\\n具体来说，LangChain 的核心特点和作用包括：\\n\\n1. **模块化设计**  \\n   LangChain 提供了模块化的组件，如链（Chains）、记忆（Memory）、代理（Agents）、工具（Tools）等，方便开发者将语言模型的不同能力组合起来，构建复杂的对话或文本生成流程。\\n\\n2. **多模型支持**  \\n   助力在同一应用中灵活地调用不同的语言模型（如OpenAI的GPT系列、Anthropic、Cohere等），支持多样的后端选择和集成。\\n\\n3. **记忆管理**  \\n   通过内置的记忆组件，LangChain 可以实现对话状态的存储和管理，使模型能够“记住”之前的上下文，提升交互的连贯性和智能度。\\n\\n4. **整合外部工具和数据**  \\n   支持与外部API、数据库和知识库的集成，使得语言模型不仅仅局限于文本生成，还能访问实时数据和执行具体操作。\\n\\n5. **方便的开发体验**  \\n   通过简单的接口和丰富的文档，降低了构建复杂语言模型应用的门槛，促进了快速的原型开发和迭代。\\n\\n总结来说，LangChain 是一个帮助开发者高效构建复杂、大规模语言模型应用的开源框架，它结合了多模型调用、上下文管理和外部工具集成等核心能力，在大模型生态中扮演着连接基础语言模型与实际应用需求的重要桥梁角色。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 397, 'prompt_tokens': 29, 'total_tokens': 426, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'input_tokens': 0, 'output_tokens': 0, 'input_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-2025jM5DeXjEUUcZtwwSVXunPI2FF', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b36da-92a1-71c1-bf42-ca0ffce03785-0' usage_metadata={'input_tokens': 29, 'output_tokens': 397, 'total_tokens': 426, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:46:23.420753Z",
     "start_time": "2025-12-19T13:46:18.009695800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者。\"),\n",
    "(\"user\", \"{input}\")\n",
    "])\n",
    "# 使用输出解析器\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么? 用JSON格式回复，问题用question，回答用answer\"})"
   ],
   "id": "48a6b96e1f8c4a89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'LangChain是什么?',\n",
       " 'answer': 'LangChain是一个用于构建基于语言模型的应用程序的框架。它提供了工具和组件，帮助开发者将大型语言模型（如GPT）与外部数据源、链式操作和自定义逻辑集成，从而构建复杂的、可扩展的自然语言处理应用。LangChain支持多种数据连接、记忆管理和代理机制，广泛应用于聊天机器人、问答系统、文本生成等领域。'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T13:46:35.308208600Z",
     "start_time": "2025-12-19T13:46:30.811889800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"你是世界级的技术文档编写者。输出格式要求：{format_instructions}\"),\n",
    "(\"user\", \"{input}\")\n",
    "])\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么?\",\"format_instructions\":output_parser.get_format_instructions()})\n",
    "# 使用输出解析器"
   ],
   "id": "35cd1d964e4fab28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangChain',\n",
       " 'description': 'LangChain是一个用于构建基于语言模型的应用程序的框架。它提供了工具和组件，帮助开发者更方便地将大型语言模型（如GPT-4）集成到各种应用中，支持对话管理、信息检索、链式调用等功能。',\n",
       " 'key_features': ['简化与大型语言模型的交互',\n",
       "  '支持链式调用（链式任务执行）',\n",
       "  '集成多种数据源和工具',\n",
       "  '支持上下文管理和记忆功能',\n",
       "  '方便构建复杂的自然语言处理应用'],\n",
       " 'use_cases': ['智能问答系统', '自动化文档生成', '对话机器人', '数据分析与报告生成', '辅助编程和代码生成'],\n",
       " 'official_website': 'https://python.langchain.com/'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T14:03:22.283539800Z",
     "start_time": "2025-12-19T14:03:15.930730300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "\n",
    "# 设置超时时间\n",
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://yiqiml.xyz/topic/7\",\n",
    "    # 可以添加请求头和超时设置\n",
    "    header_template={\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "    }\n",
    ")\n",
    "# 设置超时时间（秒）\n",
    "loader.requests_kwargs = {'timeout': 10}\n",
    "docs = loader.load()\n",
    "print(f\"加载的文档数量: {len(docs)}\")\n",
    "if docs:\n",
    "    print(f\"第一个文档的内容长度: {len(docs[0].page_content)}\")\n",
    "\n",
    "\n",
    "# 对于嵌入模型，这里通过 API调用RAG(检索增强生成)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=\"sk-aoW73w2p4eqRWaYaBb4aD05dDa8f497c87E182A7De4fC86e\",\n",
    "    base_url=\"https://api.apiyi.com/v1\"  # 确保有 /v1\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(f\"分割后的文档数量: {len(documents)}\")\n",
    "\n",
    "# 只有在有文档时才创建向量存储\n",
    "if documents:\n",
    "    vector = FAISS.from_documents(documents, embeddings)\n",
    "    print(\"向量存储创建成功!\")\n",
    "else:\n",
    "    print(\"错误: 没有文档可以创建向量存储\")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "retriever = vector.as_retriever()\n",
    "retriever.search_kwargs = {\"k\": 3}\n",
    "docs = retriever.invoke(\"故事讲了什么内容\")\n",
    "# for i,doc in enumerate(docs):\n",
    "# print(f\"⭐第{i+1}条规定：\")\n",
    "# print(doc)\n",
    "# 6.定义提示词模版\n",
    "prompt_template = \"\"\"\n",
    "你是一个问答机器人。\n",
    "你的任务是根据下述给定的已知信息回答用户问题。\n",
    "确保你的回复完全依据下述已知信息。不要编造答案。\n",
    "如果下述已知信息不足以回答用户的问题，请直接回复\"我无法回答您的问题\"。\n",
    "已知信息:\n",
    "{info}\n",
    "用户问：\n",
    "{question}\n",
    "请用中文回答用户问题。\n",
    "\"\"\"\n",
    "# 7.得到提示词模版对象\n",
    "template = PromptTemplate.from_template(prompt_template)\n",
    "# 8.得到提示词对象\n",
    "prompt = template.format(info=docs, question='故事主角是谁？')\n",
    "## 9. 调用LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=\"sk-aoW73w2p4eqRWaYaBb4aD05dDa8f497c87E182A7De4fC86e\",\n",
    "    base_url=\"https://api.apiyi.com/v1\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)\n"
   ],
   "id": "8473e4a8d923bed1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的文档数量: 1\n",
      "第一个文档的内容长度: 2901\n",
      "分割后的文档数量: 7\n",
      "向量存储创建成功!\n",
      "故事的主角是老婆和她的宝宝。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T14:04:39.614276400Z",
     "start_time": "2025-12-19T14:04:36.889795100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8.得到提示词对象\n",
    "prompt = template.format(info=docs, question='故事内容')\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "id": "1791d1eeb82a1ce6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "故事内容描述了一位母亲在喂奶的同时，和宝宝之间发生的一些有趣和亲密的互动。故事中的母亲非常关注她的宝宝，几乎将全部心思都放在宝宝身上，几乎没有夫妻生活。但在宝宝熟睡后，她仍然温柔地照顾丈夫，给他按摩以表示关心。这个故事展示了母亲对孩子的爱和对家庭的投入。\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T14:21:47.906112500Z",
     "start_time": "2025-12-19T14:21:44.325715500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"中华人民共和国民法典是新中国第一部以法典命名的法律。\"),\n",
    "    Document(page_content=\"民法典于2021年1月1日起施行。\"),\n",
    "]\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=\"sk-aoW73w2p4eqRWaYaBb4aD05dDa8f497c87E182A7De4fC86e\",\n",
    "    base_url=\"https://api.apiyi.com/v1\"  # 确保有 /v1\n",
    ")\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"CivilCodeRetriever\",\n",
    "    \"搜索有关中华人民共和国民法典的信息。关于中华人民共和国民法典的任何问题，您必须使用此工具!\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ],
   "id": "18b05172405c3583",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_openai_tools_agent' from 'langchain.agents' (C:\\Users\\ralph\\.conda\\envs\\LangChan-Tutorial\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchainhub\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_openai_tools_agent, AgentExecutor\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_openai\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatOpenAI\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tool\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'create_openai_tools_agent' from 'langchain.agents' (C:\\Users\\ralph\\.conda\\envs\\LangChan-Tutorial\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T14:22:50.576531300Z",
     "start_time": "2025-12-19T14:22:47.199695400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langchainhub\n",
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "import os\n",
    "\n",
    "# 跳过代理\n",
    "os.environ['NO_PROXY'] = '*'\n",
    "os.environ['HTTP_PROXY'] = ''\n",
    "os.environ['HTTPS_PROXY'] = ''\n",
    "\n",
    "# 从 hub 拉取 prompt (如果网络有问题可能会失败)\n",
    "try:\n",
    "    prompt = langchainhub.pull(\"hwchase17/openai-tools-agent\")\n",
    "except:\n",
    "    # 如果拉取失败，手动创建 prompt\n",
    "    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"你是一个有帮助的助手，可以使用工具来回答问题。\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "\n",
    "# 创建 LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=\"sk-aoW73w2p4eqRWaYaBb4aD05dDa8f497c87E182A7De4fC86e\",\n",
    "    base_url=\"https://api.apiyi.com/v1\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "# 创建工具（假设 retriever 已定义）\n",
    "def search_civil_code(query: str) -> str:\n",
    "    \"\"\"搜索民法典内容\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "retriever_tool = Tool(\n",
    "    name=\"CivilCodeRetriever\",\n",
    "    description=\"搜索有关中华人民共和国民法典的信息\",\n",
    "    func=search_civil_code\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]\n",
    "\n",
    "# 创建 agent（使用新版本的函数名）\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 提问\n",
    "result = agent_executor.invoke({\"input\": \"民法典中关于婚姻的规定是什么？\"})\n",
    "print(f\"\\n回答: {result['output']}\")\n"
   ],
   "id": "772211acb1ea4238",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_openai_tools_agent' from 'langchain.agents' (C:\\Users\\ralph\\.conda\\envs\\LangChan-Tutorial\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchainhub\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01magents\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m create_openai_tools_agent, AgentExecutor\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_openai\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ChatOpenAI\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Tool\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'create_openai_tools_agent' from 'langchain.agents' (C:\\Users\\ralph\\.conda\\envs\\LangChan-Tutorial\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T14:18:14.891165300Z",
     "start_time": "2025-12-19T14:18:14.866622500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ],
   "id": "dc006edc00a6ce6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e842b8d9784143"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
